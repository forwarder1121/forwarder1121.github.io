# [논문 리뷰] VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION



논문의 전문은 [여기](https://arxiv.org/pdf/1409.1556)에서 확인할 수 있다.



---

# 0. Abstract

이 연구는 대규모 이미지 분류 task에서 CNN의 depth가 정확도에 미치는 영향을 조사한다.

이 논문을 발표한 Oxford 연구 팀은 매우 작은 convolution filter (3 x 3)을 이용하여 depth를 깊게하여 ImageNet Challenge 2014에서 1위와 2위를 차지하였다. 또한 이 모델은 ImageNet datatsets뿐 아니라 다른 데이터셋에서도 SOTA의 성능을 달성하는 우수한 성능을 보인다.



---



# 1. Introduction

CNN은 다양한 기술 발전에 의해 대규모 이미지, 비디오 인식에서 큰 성공을 거두었다. 특히 ILSVRC(ImageNet Large-Scale Visual Recognition Challenge)가 다양한 이미지 인식 모델을 검증하는 시험대가 됨으로써 기술 발전의 원동력이 되었다.

CNN이 CV에서 활발하게 사용됨으로써 기존 모델보다 정확도 향상을 위해 많은 시도들이 있어 왔다. 예를 들어, smaller receptive window size와 smaller stride 를 사용하는 것과, 다양한 scales 에서 training과 testing을 진행하는 것이 그 예이다. 이 논문에서는 **"depth"**를 깊게하여 그 정확도를 높이는 연구를 진행한다.

결론적으로 CNN의 depth를 증가시킴으로써 ILSVRC에서 SOTA 정확도를 얻었을 뿐 아니라, 다른 이미지 인식 데이터 셋에서도 일반적으로 좋은 성능을 거둘 수 있음을 확인하였다.



---



# 2. ConvNet Configurations

Oxford 팀은 연구의 정확성을 위해 depth만을 변인으로 놓고, 나머지 모든 설정은 동일하게 유지하였다.

모델의 기본적인 소개를 2.1절, 구체적인 설명은 2.2절, 다른 연구와 차별점은 2.3절에서 소개하고 있다.



## 2.1 Architecture

모델의 아키텍쳐는 아래 그림과 같다.

![Imgur](https://i.imgur.com/qS1ZNWI.png)

학습되는 동안에 모델은 224 x 224 x 3 크기의 이미지를 input으로 받는다. 이 input은 매우 작은 3x3 receptive field를 가진 CNN layer를 통과하고, pooling layer를 거친다. 또 1 x 1 receptive field를 가진 모델도 실험에 고안되었는데, 이는 input channel의 선형 변환이라 생각할 수 있다.

CNN layer를 통과한 후에는 3개의 [Fully-Connected(FC) layer](https://dsbook.tistory.com/59)를 통과한다. 이 FC 구성은 모든 모델이 동일하다.

모든 은닉층은 활성화 함수로 ReLU 함수를 사용하고 있으며, Local Response Normalisation(LRN)은 ILSVRC 데이터셋에서 효과가 없음으로 하나의 모델에서만 사용하였다.





## 2.2 Configurations

모델 구성은 아래 표와 같다.



![image](https://github.com/forwarder1121/forwarder1121.github.io/assets/66872094/eb50ce9e-8def-458b-87bb-73814c96c63f)

A~E 모델이 설정되었는데, 이는 "depth"만 차이를 둔 모델이고, 11개의 layer인 A부터 시작하여 19개의 layer를 가진 E순으로 점점 더 층이 깊어지는 모델이다. CNN layer의 parmeter는 "conv <receptive field size>-<number of channels>"로 기술되어 있다. 예를 들어, conv3-512는 3x3 receptive field를 가지며 512 channels를 가진 CNN layer를 나타낸다. channels은 max pooling layer를 지날때마다 2배씩 커진다.

![image](https://github.com/forwarder1121/forwarder1121.github.io/assets/66872094/c2758610-f853-44b1-8f54-6d764883e4b4)

위 표는 parameter의 개수를 나타내는데, 더 깊은 layer를 가짐에도 불구하고 더 큰 CNN layer와 recptive fields를 가진 다른 모델의 parameter(144M) 보다 크기 않다는 것을 나타냄으로써 경제성이 있는 모델임을 보이고 있다.